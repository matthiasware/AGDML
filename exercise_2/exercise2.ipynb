{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 2 - The Right Fit (25 Points)\n",
    "\n",
    "In this exercise you will learn about a new type of regression - the polynomial regression. With polynomial regression it is possible to fit a nonlinear relationship between the dependent and the independent variables, although the problem of estimating the parameters is linear and can be solved with the standard OLS approach.\n",
    "\n",
    "The idea here is to learn a bunch of (polynomial) models on the same data set and explore the meaning of over- and underfitting the data.\n",
    "\n",
    "In a second part, we will use Leave One Out Crossvalidation to find a good regularization parameter on the Boston Housing dataset.\n",
    "\n",
    "In the event of a persistent problem, do not hesitate to contact the course instructors under\n",
    "- paul.kahlmeyer@uni-jena.de\n",
    "\n",
    "### Submission\n",
    "\n",
    "- Deadline of submission:\n",
    "        05.05.2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We now have a new dataset saved as `train.npy`.\n",
    "\n",
    "### Task 1 (1 Point)\n",
    "Load this Dataset using the [`np.load`](https://numpy.org/doc/stable/reference/generated/numpy.load.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load train.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of the dataset represent the variables. Let `X` be the explanatory variable in the first column and `Y` be the variable we want to predict in the second column. \n",
    "\n",
    "### Task 2 (1 Point)\n",
    "Visualize the data with a scatterplot of `X` against `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: scatter plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "As you can see, the relationship between the dependent variable and the explanatory one does not seem to be linear and the standard linear regression from the lecture will not perform well. One way to account for such a non linear relationship is called [polynomial regression](https://en.wikipedia.org/wiki/Polynomial_regression). For a scalar explanatory variable `X` and a scalar dependent variable `Y`, the data generation model is:\n",
    "\n",
    "$$\n",
    "Y_i = \\theta_0 + \\theta_1 * X_i + \\theta_2 X_i^2 + \\dots + \\theta_d X_i^d  + \\epsilon_i = \\sum_{j=0}^d \\theta_i * X_i^j + \\epsilon_i\n",
    "$$\n",
    "where $d$ is called degree. Although the relationship between the dependent and the explanatory variable is non linear, the problem of estimating the parameters $\\theta$ is linear. By vectorizing the model, this becomes obvious:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    Y_1 \\\\\n",
    "    Y_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    Y_n\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    \\theta_0 \\\\\n",
    "    \\theta_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\theta_d\n",
    "\\end{bmatrix}^T\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 & \\dots & 1\\\\\n",
    "    X_1 & X_2 & \\dots & X_n\\\\\n",
    "    \\vdots&\\vdots&\\vdots&\\vdots\\\\\n",
    "    X_1^d & X_2^d &\\dots & X_n^d\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "    \\epsilon_1 \\\\\n",
    "    \\epsilon_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\epsilon_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This linear model can now be fit with the ordinary-least-squares MLE approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (2 Points)\n",
    "Implement a function `poly` to create the design matrix for the polynomial regression. It should take two arguments:\n",
    "- `X` : dataset $X_1,\\dots,X_n$\n",
    "- `degree`: degree of polynomial ($d$ from above definition)\n",
    "\n",
    "and return the design matrix from the above definition. \n",
    "\n",
    "Verify the correctness of your implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly(x, degree):\n",
    "    #TODO: return polynomial design matrix\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (3 Points)\n",
    "Implement a class `PolyReg` that fits a polynomial model with ordinary least squares. Regularize your maximum-likelihood problem with ridge regression. The function returns the parameter vector.\n",
    "\n",
    "Hint: Recycle the `LinReg` class from the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyReg():\n",
    "    def __init__(self, d, c=0):\n",
    "        # TODO: create attributes d, c, theta \n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        # TODO: estimate theta\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # TODO: predict labels\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "Next we want to fit a series of models of multiple degrees and visualise them alongside the data.\n",
    "\n",
    "We want to use the following polynomial degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model degrees\n",
    "model_degrees = [0, 1, 2, 3, 6, 9, 12, 15, 18, 21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (3 Points)\n",
    "\n",
    "For each polynomial degree:\n",
    "1. Learn the polynomial model\n",
    "2. Plot the data \n",
    "3. Plot the regression line\n",
    "\n",
    "Plot each model in a separate plot. Use a scatter plot for the data.\n",
    "\n",
    "Additionaly experiment what happens if you change the values for the regularization parameter $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Learn models and visualize regression lines\n",
    "\n",
    "# TODO: What effect does c have on the regression lines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "To evaluate the models, we need a measure of fit, that tells us how well the model fits the data. The standard measure for continuously distributed data is the [\"root mean squared error\" (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation). Given the dependent variable $Y \\in \\mathbb{R}^n$ and its prediction $\\hat{Y} = f(X, \\theta) \\in \\mathbb{R}^n$, the RMSE is defined as:\n",
    "\n",
    "$$\n",
    "\\text{RMSE}(Y, \\hat{Y}) = \\sqrt{\\frac{1}{n} \\sum_{i}^n (Y_i - \\hat{Y}_i)^2}\n",
    "$$\n",
    "\n",
    "### Task 6 (2 Points)\n",
    "Implement a `rmse` function that returns the RMSE of a vector of observations $Y$ and its predictions $\\hat{Y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(Y, Y_hat):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to estimate which polynomial estimation fits best to our data.\n",
    "More complex models will in general yield better results on the data that was used to train them, but the quality of the model is determined by its \"generalizability\" (\"how well does the model perform on data that it has not seen before?\"). \n",
    "\n",
    "To evaluate this performance, we split the data in two sets:\n",
    "- trainset (`train.npy`)\n",
    "- testset (`test.npy`)\n",
    "\n",
    "where we train our predictor on the trainset and evaluate the generalizability on the testset.\n",
    "\n",
    "### Task 7 (1 Point)\n",
    "\n",
    "Load the testset (stored as `test.npy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: load test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 (2 Points)\n",
    "To estimate the quality of our models:\n",
    "- fit 20 polynomial models of degree 0 to 19 on the trainset.\n",
    "- calculate the RMSE of all the models on the trainset.\n",
    "- calculate the RMSE of all the models on the testset.\n",
    "\n",
    "Set the regularization parameter to some fixed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate train- and test RMSEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9 (1 Point)\n",
    "Now visualize the training RMSE and testing RMSE in dependence of the degree of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot RMSEs against polynomial degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the two curves of the previously generated figure you can determine the fit of the models.\n",
    "\n",
    "- Underfitting: train- and test RMSE are high\n",
    "- Overfitting: train RMSE is low, test RMSE is high\n",
    "- Just right: train- and test RMSE are low\n",
    "\n",
    "### Task 10 (1 Point)\n",
    "List briefly:\n",
    "- which models underfit\n",
    "- which models overfit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization on Housing Data\n",
    "\n",
    "In this second part we want to explore the effect of regularization on the [Boston Housing dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html). Each item in this dataset represents an area in Boston, Massachusetts.\n",
    "\n",
    "Variables:\n",
    "\n",
    "1. CRIM - per capita crime rate by town\n",
    "2. ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3. INDUS - proportion of non-retail business acres per town.\n",
    "4. CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "5. NOX - nitric oxides concentration (parts per 10 million)\n",
    "6. RM - average number of rooms per dwelling\n",
    "7. AGE - proportion of owner-occupied units built prior to 1940\n",
    "8. DIS - weighted distances to five Boston employment centres\n",
    "9. RAD - index of accessibility to radial highways\n",
    "10. TAX - full-value property-tax rate per 10,000 Dollar\n",
    "11. PTRATIO - pupil-teacher ratio by town\n",
    "12. B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13. LSTAT - % lower status of the population\n",
    "14. MEDV - Median value of owner-occupied homes in $1000's\n",
    "\n",
    "The dataset is stored as a numpy array and thus without variable names. The i-th variable corresponds to the i-th column of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11 (1 Point)\n",
    "\n",
    "Load the Boston Housing Dataset stored in `housing.npy`, standardize it and split it into features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load dataset\n",
    "\n",
    "# TODO: standardize \n",
    "\n",
    "# TODO: split into features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that our samples are of a dimension $>1$ and therefore we cannot apply polynomial regression as introduced above. Therefore we will simply focus on linear regression with Ridge Regression again.\n",
    "\n",
    "### Task 12 (1 Point)\n",
    "\n",
    "Scikit-learn provides a [Ridge Regression class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) use it to fit a linear model on our data. Determine the RMSE on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: use ridge regression from scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably observed, that we still have no clue on how to set the regularization parameter $c$ ($\\alpha$ in the scikit-learn implementation). One way to find good hyperparameters is by **crossvalidation**.\n",
    "\n",
    "With [crossvalidation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)), we want to assess how well a estimator can generalize on new, unseen data.\n",
    "\n",
    "There are several types of crossvalidation, here we want to use **Leave One Out Crossvalidation** (LOOCV).\n",
    "\n",
    "The principle is quite simple: For $m$ samples, we train $m$ estimators - each one taking a single sample for testing and the other samples for training. The average RMSE of all the estimators is then taken as an estimation for the quality of $c$.\n",
    "\n",
    "### Task 13 (4 Points)\n",
    "\n",
    "Implement a function `loocv`, that takes a Ridge Regression object (`estimator`), samples, labels and outputs the cross_validation RMSE determined with the following steps:\n",
    "\n",
    "1. For each sample:\n",
    "    1. Use this sample as testdata, the other samples as traindata\n",
    "    2. Learn estimator\n",
    "    3. Estimate RMSE on testdata\n",
    "2. Average estimated RMSEs\n",
    "\n",
    "Test your function for $c=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv(estimator, samples, labels):\n",
    "    # TODO: Implement leave one out crossvalidation for Ridge Regression\n",
    "    pass\n",
    "\n",
    "\n",
    "# TODO: test for c=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14 (2 Points)\n",
    "Now systematically test values for $c$ on their LOOCV performance.\n",
    "\n",
    "What value for $c$ would you recommend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: LOOCV for different regularization parameters\n",
    "    \n",
    "# TODO: What c would you recommend?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
