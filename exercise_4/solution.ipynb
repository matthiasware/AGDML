{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 - Spelling Correction with Naive Bayes (30 Points)\n",
    "\n",
    "In this exercise you will learn about a fun application of the *Naive Bayes* classifier: Spelling correction. For the\n",
    "informal and vivid character of natural language, the correction of syntactic and semantic errors in written language is an extremely hard task. Here you will challenge this problem by applying one of the simplest classification\n",
    "algorithms, namely Naive Bayes and see how it performs.\n",
    "\n",
    "In the event of a persistent problem, do not hesitate to contact the course instructors under\n",
    "- christoph.staudt@uni-jena.de\n",
    "\n",
    "### Submission\n",
    "\n",
    "- Deadline of submission:\n",
    "        19.05.2021 23:59\n",
    "- Submission on [moodle page](https://moodle.uni-jena.de/course/view.php?id=28746)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "This exercise is based on section 5.1 in *Speech and Language Processing* by Daniel Jurafsky & James H. We will implement its \"Noisy Channel Model\" and required functions stept by step, but if you are interested in reading about it in one go or with more explanations you can do so in the file `chapter5.pdf`.\n",
    "\n",
    "\n",
    "## Problem statement\n",
    "We frame spelling correction as a classification problem and use Bayesian inference to obtain results. Although the\n",
    "basic problem statement is straightforward, there is plenty of room to improve the used models, initially\n",
    "published by Peter Norvig.\n",
    "\n",
    "Given an observation $x$ and a corpus of words $W$. For spelling correction, we want to find the most likely correction $w\\in W$ for $x$.\n",
    "In other words, we are looking for \n",
    "\n",
    "\\begin{align*}\n",
    "\\text{argmax}_{w\\in W}p(w|x)&=\\text{argmax}_{w\\in W}\\cfrac{p(x|w)p(w)}{p(x)}\\\\\n",
    "&=\\text{argmax}_{w\\in W}p(x|w)p(w)\n",
    "\\end{align*}\n",
    "\n",
    "In practice, we do not want to maximize over the complete corpus of words, but rather only over a set of candidate words $C_x\\subset W$ that depends on the observed pattern $x$.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{argmax}_{w\\in C_x}p(x|w)p(w)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model\n",
    "The probability $p(w)$ is also called prior or **language model**, since it represents our model of how words are distributed before we take $x$ into consideration.\n",
    "There are multiple classes of language models. \n",
    "The simplest class of model is the unigram model, where the probability of each word is fixed and can be obtained by using the frequency of its occurrence in a given corpus.\n",
    "Within the directory `books` you will find several `.txt` files that contain (parts) of books from the [Project Gutenberg](www.gutenberg.org). This source shall provide the basis for obtaining the corpus $W$ and for training a language model.\n",
    "\n",
    "\n",
    "### Task 1 (2 Points)\n",
    "Load the book texts from the `.txt` files, filter the alphabetic\n",
    "expressions and calculate the frequencies of occurrences of the existing words.\n",
    "What are the top 10 most occuring words, how often to they occur? \n",
    "\n",
    "Make sure to store $W$ in a data structure, where you can quickly check if $w\\in W$ for a word $w$ (see [here](https://wiki.python.org/moin/TimeComplexity)).\n",
    "\n",
    "Hints:\n",
    "- the files are encoded in utf-8\n",
    "- use [regex](https://docs.python.org/3/library/re.html) to filter for words\n",
    "- lower case the words\n",
    "- You may want to use one of the more [specialized datatypes](https://realpython.com/python-collections-module/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 55160), ('and', 32870), ('of', 28632), ('to', 27333), ('i', 21438), ('a', 21437), ('in', 17390), ('that', 14731), ('it', 13854), ('he', 12482)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: load books\n",
    "p = 'books'\n",
    "words = []\n",
    "for f in os.listdir(p):\n",
    "    content =  open(os.path.join(p,f), encoding='utf8').read()\n",
    "    words += re.findall(r'\\w+', content.lower())\n",
    "\n",
    "# TODO: count words\n",
    "n_words = len(words)\n",
    "words = collections.Counter(words)\n",
    "words.most_common(10)\n",
    "top10_words = words.most_common(10)\n",
    "print(top10_words)\n",
    "\n",
    "assert top10_words == [('the', 55160),\n",
    " ('and', 32870),\n",
    " ('of', 28632),\n",
    " ('to', 27333),\n",
    " ('i', 21438),\n",
    " ('a', 21437),\n",
    " ('in', 17390),\n",
    " ('that', 14731),\n",
    " ('it', 13854),\n",
    " ('he', 12482)] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15116"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (1 Point)\n",
    "Use the loaded corpus to implement a function that resembles our language model.\n",
    "Use relative frequencies as estimates for $p(w)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05136865749199591"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def language_model(w):\n",
    "    # TODO: implement language model\n",
    "    if w in words:\n",
    "        return words[w] / n_words\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def language_model_smoothed(w):\n",
    "    # TODO: implement language model\n",
    "    if w in words:\n",
    "        return (words[w]+1) / (n_words+1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "assert language_model('the') == 0.052811928832191914\n",
    "language_model('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Words\n",
    "Real-world-spelling-errors take multiple shapes. There are typographical errors like insertions, deletions and trans-\n",
    "positions of letters, and there are cognitive errors where the writer substitutes a wrong spelling of a homophone or\n",
    "near-homophone (e.g., dessert for desert, or piece for peace). The detection of the latter require context information\n",
    "and therefore are hard to detect. Thus we focus on the former, which are errors that were produced by the following\n",
    "operations:\n",
    "- transposition (e.g. \"catress\" for \"actress\" : \"ac\" $\\rightarrow$ \"ca\")\n",
    "- deletion (\"acress\" for \"actress\": missing \"t\")\n",
    "- substitutions (\"acress\" for \"access\": substituted \"r\" for \"c\")\n",
    "- insertions (\"actresss\" for \"actress\": added \"s\")\n",
    "\n",
    "Given an observation $x$, we create a set of possible candidates $C_x$ by applying all the possible edit operators on $x$. By concatenating operations, you can transform each word into any other arbitrary word. Yet, to keep things simply\n",
    "we only consider candidates with *at most one* edit distance away from $x$. \n",
    "\n",
    "For instance, the correction candidates for the word \"nie\", could be:\n",
    "\n",
    "\\begin{equation*}\n",
    "C_{\\text{nie}} = \\{\\text{die}, \\text{lie}, \\text{pie}, \\text{tie}, \\text{nice}, \\text{nine}, \\text{in}\\}\n",
    "\\end{equation*}\n",
    "\n",
    "### Task 3 (5 Points)\n",
    "Implement a function that creates a set of all possible correction candidates for a given observation $x$,\n",
    "that are at most one edit distance away from $x$. You do not need to concatenate operations! The function should only return a candidate $c$ if it occurs in the corpus, i.e. $ c \\in W$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transposes(x):\n",
    "    # TODO: possible transpositions\n",
    "    return [x[:i] + x[i+1]+ x[i]+ x[i+2:] for i in range(len(x)-1)] \n",
    "\n",
    "def deletes(x):\n",
    "    # TODO: possible deletes\n",
    "    return [x[:i] + x[i+1:] for i in range(len(x))]\n",
    "\n",
    "def substitutions(x):\n",
    "    # TODO: possible substitutions\n",
    "    alpha = string.ascii_lowercase\n",
    "    return [x[:i] + c + x[i+1:] for i in range(len(x)) for c in alpha]\n",
    "    \n",
    "def insertions(x):\n",
    "    # TODO: possible insertions\n",
    "    alpha = string.ascii_lowercase\n",
    "    return [x[:i] + c + x[i:] for i in range(len(x)+1) for c in alpha]\n",
    "\n",
    "def candidates(x):\n",
    "    # TODO: possible candidates\n",
    "    cands = transposes(x) + deletes(x) + substitutions(x) + insertions(x)\n",
    "    cands.append(x)\n",
    "    cands = list(set(cands))\n",
    "    return [w for w in cands if w in words]\n",
    "\n",
    "assert transposes('frod') == ['rfod', 'ford', 'frdo']\n",
    "assert deletes('frod') == ['rod', 'fod', 'frd', 'fro']\n",
    "assert substitutions('frod') == ['arod', 'brod', 'crod', 'drod', 'erod', 'frod', 'grod', 'hrod', 'irod', 'jrod', 'krod', 'lrod', 'mrod', 'nrod', 'orod', 'prod', 'qrod', 'rrod', 'srod', 'trod', 'urod', 'vrod', 'wrod', 'xrod', 'yrod', 'zrod', 'faod', 'fbod', 'fcod', 'fdod', 'feod', 'ffod', 'fgod', 'fhod', 'fiod', 'fjod', 'fkod', 'flod', 'fmod', 'fnod', 'food', 'fpod', 'fqod', 'frod', 'fsod', 'ftod', 'fuod', 'fvod', 'fwod', 'fxod', 'fyod', 'fzod', 'frad', 'frbd', 'frcd', 'frdd', 'fred', 'frfd', 'frgd', 'frhd', 'frid', 'frjd', 'frkd', 'frld', 'frmd', 'frnd', 'frod', 'frpd', 'frqd', 'frrd', 'frsd', 'frtd', 'frud', 'frvd', 'frwd', 'frxd', 'fryd', 'frzd', 'froa', 'frob', 'froc', 'frod', 'froe', 'frof', 'frog', 'froh', 'froi', 'froj', 'frok', 'frol', 'from', 'fron', 'froo', 'frop', 'froq', 'fror', 'fros', 'frot', 'frou', 'frov', 'frow', 'frox', 'froy', 'froz']\n",
    "assert insertions('frod') == ['afrod', 'bfrod', 'cfrod', 'dfrod', 'efrod', 'ffrod', 'gfrod', 'hfrod', 'ifrod', 'jfrod', 'kfrod', 'lfrod', 'mfrod', 'nfrod', 'ofrod', 'pfrod', 'qfrod', 'rfrod', 'sfrod', 'tfrod', 'ufrod', 'vfrod', 'wfrod', 'xfrod', 'yfrod', 'zfrod', 'farod', 'fbrod', 'fcrod', 'fdrod', 'ferod', 'ffrod', 'fgrod', 'fhrod', 'firod', 'fjrod', 'fkrod', 'flrod', 'fmrod', 'fnrod', 'forod', 'fprod', 'fqrod', 'frrod', 'fsrod', 'ftrod', 'furod', 'fvrod', 'fwrod', 'fxrod', 'fyrod', 'fzrod', 'fraod', 'frbod', 'frcod', 'frdod', 'freod', 'frfod', 'frgod', 'frhod', 'friod', 'frjod', 'frkod', 'frlod', 'frmod', 'frnod', 'frood', 'frpod', 'frqod', 'frrod', 'frsod', 'frtod', 'fruod', 'frvod', 'frwod', 'frxod', 'fryod', 'frzod', 'froad', 'frobd', 'frocd', 'frodd', 'froed', 'frofd', 'frogd', 'frohd', 'froid', 'frojd', 'frokd', 'frold', 'fromd', 'frond', 'frood', 'fropd', 'froqd', 'frord', 'frosd', 'frotd', 'froud', 'frovd', 'frowd', 'froxd', 'froyd', 'frozd', 'froda', 'frodb', 'frodc', 'frodd', 'frode', 'frodf', 'frodg', 'frodh', 'frodi', 'frodj', 'frodk', 'frodl', 'frodm', 'frodn', 'frodo', 'frodp', 'frodq', 'frodr', 'frods', 'frodt', 'frodu', 'frodv', 'frodw', 'frodx', 'frody', 'frodz']\n",
    "assert candidates(\"frod\") == ['food', 'frog', 'trod', 'fro', 'ford', 'from', 'rod']\n",
    "assert candidates(\"that\") == ['chat', 'that', 'tat', 'hat', 'than', 'what']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Model\n",
    "Recall the problem statement:\n",
    "The probability $p(x|w)$ for $w\\in C\\subset W$ is also called **error model**, since it represents how likely $w$ was mispelled as the observed pattern $x$.\n",
    "\n",
    "A very simple error model can be achieved by setting\n",
    "\n",
    "\\begin{equation*}\n",
    "p(x|w) := p(w),\n",
    "\\end{equation*}\n",
    "\n",
    "which reduces our initial problem to: \n",
    "\n",
    "\\begin{align*}\n",
    "\\text{argmax}_{w\\in C}p(w)p(w) = \\text{argmax}_{w\\in C}p(w).\n",
    "\\end{align*}\n",
    "\n",
    "### Task 4 (2 Points)\n",
    "Implement a function `correction`, that returns $\\text{argmax}_{w\\in W}p(w|x)$ for a given input $x$, based on the above definition.\n",
    "\n",
    "Also think about what `correction` should return\n",
    "- if $x$ is a known word?\n",
    "- if $x$ is unknown and has no correction candidates?\n",
    "\n",
    "<details><summary>Answers</summary>\n",
    "In both cases x should be returned.\n",
    "</details>\n",
    "\n",
    "What is the correction for the word \"frod\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correction(x): \n",
    "    # TODO: return correction candidate\n",
    "    if x in words:\n",
    "        return x\n",
    "    else:\n",
    "        can = candidates(x)\n",
    "        if len(can)>0:\n",
    "            probs = [language_model(c) for c in can]\n",
    "            return can[np.argmax(probs)]\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "assert correction('sucess') == 'success'\n",
    "correction('frod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (2 Points)\n",
    "The file `dataset.p` contains a list of spelling data from several [corpora of misspellings](https://www.dcs.bbk.ac.uk/~ROGER/corpora.html), where each item contains a tuple of the form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{misspelled word, correct word}\n",
    "\\end{equation}\n",
    "\n",
    "The dataset has been preprocessed, so each misspelling is one edit distance away from the correct word.\n",
    "Load the dataset and split it into a training (80%) and test set (20%). Since you just need to do a single split you can use [np.random.shuffle(dataset)](https://numpy.org/doc/stable/reference/random/generated/numpy.random.shuffle.html).\n",
    "\n",
    "The file was created using [pickle](https://wiki.python.org/moin/UsingPickle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priveliged\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load dataset (1 Point)\n",
    "dataset = pickle.load(open('dataset.p', 'rb') )\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "dataset = np.load('dataset.p', allow_pickle=True)\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "assert isinstance(dataset, np.ndarray)\n",
    "# TODO: Split into train- and testset (1 Point)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(dataset)\n",
    "train_perc = 0.8\n",
    "train_amount = int(train_perc*len(dataset))\n",
    "trainset = dataset[:train_amount]\n",
    "testset = dataset[train_amount:]\n",
    "\n",
    "assert trainset[4,0] == 'priveliged'\n",
    "assert trainset[37,0] == 'san'\n",
    "assert testset[4,0] == 'wishas'\n",
    "assert testset[37,0] == 'yow'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (3 Points)\n",
    "\n",
    "\n",
    "Implement a function `validate`, that takes a correction function (takes a word, outputs a suggestion) tries to correct the typos in the testset. Use only the data, where the correct word is actually in our word corpus $W$.\n",
    "\n",
    "`validate` should return a list of the cases, where the correction failed, as well as the success rate (percentage of correctly corrected typos).\n",
    "\n",
    "What is your success rate? On which words did your spelling correction fail and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.7011669203450026\n",
      "Observed: ommitting\tCorrected: committing\tActual: omitting\n",
      "Observed: put\tCorrected: put\tActual: but\n",
      "Observed: remove\tCorrected: remove\tActual: removed\n",
      "Observed: hungary\tCorrected: hungary\tActual: hungry\n",
      "Observed: hide\tCorrected: hide\tActual: hid\n",
      "Observed: rick\tCorrected: dick\tActual: rich\n",
      "Observed: couse\tCorrected: house\tActual: cause\n",
      "Observed: move\tCorrected: move\tActual: moved\n",
      "Observed: thing\tCorrected: thing\tActual: think\n",
      "Observed: looses\tCorrected: loose\tActual: loses\n",
      "589\n"
     ]
    }
   ],
   "source": [
    "def validate(correction_function):\n",
    "    # TODO: estimate success rate\n",
    "        \n",
    "    failed = []\n",
    "    count = 0\n",
    "    for wrong, right in testset:\n",
    "        if right in words:\n",
    "            count += 1\n",
    "            c = correction_function(wrong)\n",
    "            if c != right: \n",
    "                failed.append((right, c, wrong))\n",
    "    success_rate = 1 - (len(failed) / count)\n",
    "    return failed, success_rate\n",
    "\n",
    "# TODO: estimate success rate, view failed corrections\n",
    "failed, sr = validate(correction)\n",
    "assert sr ==  0.7011669203450026\n",
    "print(f'Success rate: {sr}')\n",
    "for right, c , wrong in failed[:10]:\n",
    "    print(f'Observed: {wrong}\\tCorrected: {c}\\tActual: {right}')\n",
    "    \n",
    "print(len(failed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcffa905",
   "metadata": {},
   "source": [
    "As you can see if the wrong word is in our dictionary that will automatically lead to an error since we just return it again. Fixing these kind of errors requires to go beyond the unigramm model and take the surrrounding context of the word into consideration. We won't do this here so next overwrite the validate function and skip cases where the wrong word is in the dictionary. (Still Task 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4b7370bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.7988439306358381\n",
      "Observed: ommitting\tCorrected: committing\tActual: omitting\n",
      "Observed: rick\tCorrected: dick\tActual: rich\n",
      "Observed: couse\tCorrected: house\tActual: cause\n",
      "Observed: looses\tCorrected: loose\tActual: loses\n",
      "Observed: tham\tCorrected: that\tActual: them\n",
      "Observed: folloy\tCorrected: follow\tActual: folly\n",
      "Observed: leat\tCorrected: let\tActual: left\n",
      "Observed: borde\tCorrected: bore\tActual: bored\n",
      "Observed: bast\tCorrected: last\tActual: best\n",
      "Observed: oll\tCorrected: all\tActual: oil\n",
      "348\n"
     ]
    }
   ],
   "source": [
    "def validate(correction_function):\n",
    "    # TODO: estimate success rate\n",
    "        \n",
    "    failed = []\n",
    "    count = 0\n",
    "    for wrong, right in testset:\n",
    "        if right in words and wrong not in words:\n",
    "            count += 1\n",
    "            c = correction_function(wrong)\n",
    "            if c != right: \n",
    "                failed.append((right, c, wrong))\n",
    "    success_rate = 1 - (len(failed) / count)\n",
    "    return failed, success_rate\n",
    "\n",
    "# TODO: estimate success rate, view failed corrections\n",
    "failed, sr = validate(correction)\n",
    "assert sr ==  0.7988439306358381\n",
    "print(f'Success rate: {sr}')\n",
    "for right, c , wrong in failed[:10]:\n",
    "    print(f'Observed: {wrong}\\tCorrected: {c}\\tActual: {right}')\n",
    "    \n",
    "print(len(failed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations and confusion\n",
    "\n",
    "By analyzing the output of your spelling corrector, you find examples where the corrected word is indeed a real\n",
    "word, but not the expected one, for example:\n",
    "\n",
    "\\begin{equation*}\n",
    "x=\\text{\"tham\"}, w=\\text{\"them\"}, \\text{correction}=\\text{\"that\"}\n",
    "\\end{equation*}\n",
    "\n",
    "This phenomena occurs due to the simplistic nature of our error model. Currently \"that\" is suggested as correction, because the word \"that\" is more likely than the word \"them\", but this does not account for the fact that substituting an \"a\" with an \"e\" is more likely than substituting an \"m\" with a \"t\".\n",
    "\n",
    "Instead of treating each error equally, we now consider the probability of the edit required to get from $w$ to $x$. We will need four confusion matrices:\n",
    "- $\\operatorname{del}[a,b]$: count($ab$ typed as $a$), i.e. $w$ contains the character sequence $ab$, but $b$ was deleted in $x$.\n",
    "- $\\operatorname{ins}[a,b]$: count($a$ typed as $ab$), i.e. $w$ contains the character $a$ and $b$ was inserted after $a$ in $x$.\n",
    "- $\\operatorname{sub}[a,b]$: count($a$ typed as $b$), i.e. $w$ contains the character $a$, but in $x$ there is a $b$ instead of an $a$.\n",
    "- $\\operatorname{trans}[a,b]$: count($ab$ typed as $ba$), i.e. $w$ contains the character sequence $ab$, but in $x$ it was swapped to $ba$.\n",
    "\n",
    "\n",
    "In order to construct these matrices, we need a way to find out, which transformation took place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (5 Points)\n",
    "\n",
    "Implement the function `get_transformation`, which takes the correct word and the misspelled word as input. The function should output three things:\n",
    "- ID of transformation (del, ins, sub or trans)\n",
    "- a of transformation \n",
    "- b of transformation\n",
    "\n",
    "where a and b are defined for each transformation as mentioned above. You may also look at the asssertions below to get an understanding of their definitions. Insertions or deletions at the start of the word will need an a that is not in the word. We will use the character \"#\" for this. Remember, that every misspelling  is generated by only one transformation .\n",
    "\n",
    "<details>\n",
    "<summary>Open to get implementation hints</summary>\n",
    " Compare the characters of the words one by one to find the first place where they defer. Then use the length of the words and the next character to determine which transformation happened\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformation(wrong, right):\n",
    "    # TODO: returns id, x, y of transformation\n",
    "    i = 0\n",
    "    while i< len(wrong) and i < len(right) and wrong[i] == right[i]:\n",
    "        i += 1\n",
    "        \n",
    "    if len(wrong) < len(right):\n",
    "        # deletion\n",
    "        if i == 0:\n",
    "            # deletion of first letter\n",
    "            return 'del', '#', right[i]\n",
    "        else:\n",
    "            return 'del', right[i-1], right[i]\n",
    "    \n",
    "    elif len(wrong)  > len(right):\n",
    "        # insertion \n",
    "        if i == 0:\n",
    "            # insertion at first letter\n",
    "            return 'ins', '#', wrong[i]\n",
    "        else:   \n",
    "            return 'ins', right[i-1], wrong[i]\n",
    "    \n",
    "    elif (i==len(wrong)-1) or wrong[i+1] == right[i+1]:\n",
    "        # substitution\n",
    "        return 'sub', right[i], wrong[i]\n",
    "    \n",
    "    elif wrong[i+1] == right[i]:\n",
    "        # transposition\n",
    "        return 'trans', right[i], wrong[i] #or right[i+1]\n",
    "    \n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sub', 'm', 'd')\n",
      "('ins', 'm', 'm')\n",
      "('del', 'r', 'o')\n",
      "('trans', 'o', 'm')\n",
      "('del', '#', 'f')\n",
      "('ins', '#', 'a')\n"
     ]
    }
   ],
   "source": [
    "# Test cases:\n",
    "print(get_transformation('frod','from'))\n",
    "print(get_transformation('fromm', 'from'))\n",
    "print(get_transformation('frm', 'from'))\n",
    "print(get_transformation('frmo', 'from'))\n",
    "print(get_transformation('rom', 'from'))\n",
    "print(get_transformation('afrom', 'from'))\n",
    "\n",
    "\n",
    "assert get_transformation('frod','from') == ('sub', 'm', 'd')\n",
    "assert get_transformation('fromm', 'from') == ('ins', 'm', 'm')\n",
    "assert get_transformation('frm', 'from') == ('del', 'r', 'o')\n",
    "assert get_transformation('frmo', 'from') == ('trans', 'o', 'm')\n",
    "assert get_transformation('rom', 'from') == ('del', '#', 'f')\n",
    "assert get_transformation('afrom', 'from') == ('ins', '#', 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 (2 Points)\n",
    "\n",
    "Use the `get_transformation` function and the trainset to create the confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'sub': 2998, 'ins': 1743, 'trans': 636, 'del': 2543})\n",
      "7920\n",
      "7920\n",
      "{'sub': 0.37853535353535356, 'ins': 0.22007575757575756, 'trans': 0.0803030303030303, 'del': 0.3210858585858586}\n"
     ]
    }
   ],
   "source": [
    "# TODO: create confusion matrices\n",
    "alphabet = string.ascii_lowercase\n",
    "\n",
    "del_matrix = np.zeros((len(alphabet)+1, len(alphabet)))\n",
    "ins_matrix = np.zeros((len(alphabet)+1, len(alphabet)))\n",
    "sub_matrix = np.zeros((len(alphabet), len(alphabet)))\n",
    "trans_matrix = np.zeros((len(alphabet), len(alphabet)))\n",
    "\n",
    "transformation_type_counts = collections.defaultdict(int)\n",
    "\n",
    "for wrong, right in trainset:\n",
    "    transf, x, y = get_transformation(wrong, right)\n",
    "    idx_x = alphabet.find(x) # if #, then idx=-1\n",
    "    idx_y = alphabet.find(y)\n",
    "    transformation_type_counts[transf] +=1\n",
    "    if transf == 'del':\n",
    "        del_matrix[idx_x+1, idx_y] += 1 \n",
    "    elif transf == 'ins':\n",
    "        ins_matrix[idx_x+1, idx_y] += 1\n",
    "    elif transf == 'sub':\n",
    "        sub_matrix[idx_x, idx_y] += 1\n",
    "    elif transf == 'trans':\n",
    "        trans_matrix[idx_x, idx_y] += 1\n",
    "\n",
    "# As claimed above substitution of a and e much more likely\n",
    "assert sub_matrix[alphabet.find('a'),alphabet.find('e')] ==  204.0\n",
    "assert sub_matrix[alphabet.find('e'),alphabet.find('a')] ==  261.0\n",
    "assert sub_matrix[alphabet.find('m'),alphabet.find('t')] ==  0.0\n",
    "assert sub_matrix[alphabet.find('t'),alphabet.find('m')] ==  0.0\n",
    "\n",
    "assert del_matrix[0,0] == 4\n",
    "assert ins_matrix[1,3] == 1\n",
    "assert trans_matrix[5,4] == 2\n",
    "print(transformation_type_counts)\n",
    "print(transformation_type_counts['ins']+transformation_type_counts['sub']+transformation_type_counts['del']+transformation_type_counts['trans'])\n",
    "print(trainset.shape[0])\n",
    "transformation_probs = {key: value / trainset.shape[0] for key, value in transformation_type_counts.items()}\n",
    "print(transformation_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9 (1 Point)\n",
    "Visualize the confusion matrices. Are the results as you would expect?\n",
    "\n",
    "Hint: Review Solution of Exercise 1 Task 5 (Correlation matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: visualize confusion matrices\n",
    "fs = 4\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 4, figsize=(4*fs,fs))\n",
    "\n",
    "axs[0].imshow(del_matrix, cmap='gray')\n",
    "axs[0].set_title('Deletion')\n",
    "axs[0].set_yticks(ticks=np.arange(0,len(string.ascii_lowercase)+1,1))\n",
    "axs[0].set_yticklabels(labels=['#']+list(string.ascii_lowercase))\n",
    "axs[0].set_xticks(ticks=np.arange(0,len(string.ascii_lowercase),1))\n",
    "axs[0].set_xticklabels(labels=list(string.ascii_lowercase))\n",
    "\n",
    "axs[1].imshow(ins_matrix, cmap='gray')\n",
    "axs[1].set_title('Insertion')\n",
    "axs[1].set_yticks(ticks=np.arange(0,len(string.ascii_lowercase)+1,1))\n",
    "axs[1].set_yticklabels(labels=['#']+list(string.ascii_lowercase))\n",
    "axs[1].set_xticks(ticks=np.arange(0,len(string.ascii_lowercase),1))\n",
    "axs[1].set_xticklabels(labels=list(string.ascii_lowercase))\n",
    "\n",
    "axs[2].imshow(sub_matrix, cmap='gray')\n",
    "axs[2].set_title('Substitution')\n",
    "axs[2].set_xticks(ticks=np.arange(0,len(string.ascii_lowercase),1))\n",
    "axs[2].set_xticklabels(labels=list(string.ascii_lowercase))\n",
    "axs[2].set_yticks(ticks=np.arange(0,len(string.ascii_lowercase),1))\n",
    "axs[2].set_yticklabels(labels=list(string.ascii_lowercase))\n",
    "\n",
    "axs[3].imshow(trans_matrix, cmap='gray')\n",
    "axs[3].set_title('Transposition')\n",
    "axs[3].set_xticks(ticks=np.arange(0,len(string.ascii_lowercase),1))\n",
    "axs[3].set_xticklabels(labels=list(string.ascii_lowercase))\n",
    "axs[3].set_yticks(ticks=np.arange(0,len(string.ascii_lowercase),1))\n",
    "axs[3].set_yticklabels(labels=list(string.ascii_lowercase))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From confusion to probability\n",
    "The confusion matrices alone are not sufficient to estimate the error probability. In order do that we need a base count of how often that transformation could have happened. As this depends on the type of transformation, we will define the error probability $p(x|w)$ for each of them individually now. Instead of considering the whole words $x$ and $w$, we will simply look at the error on the character level $a$ and $b$.\n",
    "\n",
    "\n",
    "**Deletion**\n",
    "\n",
    "The candidate word $w$ contains the character sequence $ab$, but $b$ was deleted in $x$. To estimate how likely deleting $b$ from $ab$ is, we relate it to all occurences of $ab$. Thus, the error probability $$p_{\\operatorname{del}}(x|w) = \\operatorname{del}[a,b] / \\operatorname{count}[ab].$$\n",
    "\n",
    "As an example consider acress and actress: $$p_{\\operatorname{del}}(x=\"\\text{acress}\" | w = \"\\text{actress}\") = \\operatorname{del}[c,t] /  \\operatorname{count}[ct].$$\n",
    "\n",
    "\n",
    "**Insertion**\n",
    "\n",
    "The candidate word $w$ contains the character $a$ and $b$ was inserted after $a$ in $x$. This transformation can only happen if an $a$ was in the word, so we relate it to all occurences of $a$ as the base count and \n",
    "\n",
    "$$p_{\\operatorname{ins}}(x|w) = \\operatorname{ins}[a,b] / \\operatorname{count}[a].$$\n",
    "\n",
    "where $\\operatorname{count}[\\#]$ equals the number of words in the training set. As an example consider sactress and actress: $$p_{\\operatorname{ins}}(x=\"\\text{sactress}\" | w = \"\\text{actress}\") = \\operatorname{ins}[\\#,s] /  \\operatorname{count}[\\#].$$\n",
    "\n",
    "**Substitution**\n",
    "\n",
    "The candidate word $w$ contains the character $a$, but in $x$ there is a $b$ instead of an $a$. Again we only need to count all occurences $a$ to get the base count and \n",
    "\n",
    "$$p_{\\operatorname{sub}}(x|w) = \\operatorname{sub}[a,b] / \\operatorname{count}[a].$$\n",
    "\n",
    "As an example consider adtress and actress: $$p_{\\operatorname{sub}}(x=\"\\text{adtress}\" | w = \"\\text{actress}\") = \\operatorname{sub}[c,d] /  \\operatorname{count}[c].$$\n",
    "\n",
    "\n",
    "**Transposition**\n",
    "\n",
    "The candidate word $w$ contains the character sequence $ab$, but in $x$ it was swapped to $ba$. To estimate how likely swapping $ab$ is, we relate it to all occurences of $ab$. Thus, the error probability $$p_{\\operatorname{trans}}(x|w) = \\operatorname{trans}[a,b] / \\operatorname{count}[ab].$$\n",
    "\n",
    "As an example consider catress and actress: $$p_{\\operatorname{trans}}(x=\"\\text{catress}\" | w = \"\\text{actress}\") = \\operatorname{sub}[a,c] /  \\operatorname{count}[ac].$$\n",
    "\n",
    "To estimate these probabilities we will need to count the character occurences.\n",
    "\n",
    "### Task 10 (2 Points)\n",
    "\n",
    "Count the single and pairwaise character occurences in `trainset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6388933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 26/26 [00:08<00:00,  3.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "char_counts = np.zeros(27)\n",
    "char_pair_counts = np.zeros((27, 26))\n",
    "\n",
    "# TODO: Calculate counts\n",
    "alphabet = string.ascii_lowercase\n",
    "\n",
    "char_counts[0] = trainset.shape[0]\n",
    "for j in tqdm(range(len(alphabet))):\n",
    "    y = alphabet[j]    \n",
    "    char_counts[j+1] = sum([right.count(y) for _, right in trainset])\n",
    "    for i,x in enumerate('#'+alphabet):\n",
    "        if x == '#':\n",
    "            char_pair_counts[i,j] = sum([right.startswith(y) for _, right in trainset])\n",
    "        else:\n",
    "            char_pair_counts[i,j] = sum([right.count(x+y) for _, right in trainset])\n",
    "\n",
    "assert char_counts[0] == 7920\n",
    "assert char_counts[2] == 800\n",
    "assert char_pair_counts[0,1] == 401\n",
    "assert char_pair_counts[1,3] == 131\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f808d4",
   "metadata": {},
   "source": [
    "### Task 11 (3 Points)\n",
    "\n",
    "`char_pair_counts` contains several zeros since not all character pairs occur in the training set. To avoid divisions by zero we will use [Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing). This will also avoid zeros in the nominator, so we will use it for all transformations:\n",
    "\n",
    "$$p_{\\operatorname{del}}(x|w) = (\\operatorname{del}[a,b] + \\alpha) / (\\operatorname{count}[ab]+\\alpha).$$\n",
    "$$p_{\\operatorname{ins}}(x|w) = (\\operatorname{ins}[a,b] + \\alpha) / (\\operatorname{count}[a] + \\alpha)$$\n",
    "$$p_{\\operatorname{sub}}(x|w) = (\\operatorname{sub}[a,b] + \\alpha) / (\\operatorname{count}[a] + \\alpha)$$\n",
    "$$p_{\\operatorname{trans}}(x|w) = (\\operatorname{trans}[a,b] + \\alpha) / (\\operatorname{count}[ab] + \\alpha)$$\n",
    "Implement the noisy channel `error_model(x,w,alpha)` function, that calculates $p(x|w)$ by identifying the transformation and calculating the matching smoothed probability as defined above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "536d33b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03599395521362825\n",
      "0.0002486325211337643\n"
     ]
    }
   ],
   "source": [
    "def error_model(x,w,alpha):\n",
    "    # TODO: Calculate p(x|candidate)\n",
    "    ident, x, y = get_transformation(x, w)\n",
    "    idx_x = string.ascii_lowercase.find(x) # -1 if #\n",
    "    idx_y = string.ascii_lowercase.find(y)\n",
    "    \n",
    "    nominator = alpha\n",
    "    denominator = alpha\n",
    "    if ident == 'del':\n",
    "        denominator += char_pair_counts[idx_x+1, idx_y]\n",
    "        nominator += del_matrix[idx_x+1, idx_y]\n",
    "    elif ident == 'ins':\n",
    "        denominator += char_counts[idx_x+1]\n",
    "        nominator += ins_matrix[idx_x+1, idx_y]\n",
    "    elif ident == 'sub':\n",
    "        denominator += char_counts[idx_x+1]\n",
    "        nominator += sub_matrix[idx_x, idx_y]\n",
    "    elif ident == 'trans':\n",
    "        denominator += char_pair_counts[idx_x+1, idx_y]\n",
    "        nominator += trans_matrix[idx_x, idx_y]\n",
    "    return nominator / denominator\n",
    "\n",
    "\n",
    "assert error_model('tham', 'them', 1) == 0.03599395521362825\n",
    "assert error_model('tham', 'that', 1) == 0.0002486325211337643"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08879bc8",
   "metadata": {},
   "source": [
    "### Task 12 (2 Points)\n",
    "Based on this error model implement the `correction_noisy_channel` function that outputs the best correction candidate:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{argmax}_{w\\in C_x}p(x|w)p(w).\n",
    "\\end{align*}\n",
    "\n",
    "Use $\\alpha = 0.01$ as smoothing parameter. You can also play around with this to see how it incluences the result. \n",
    "\n",
    "Similar to task 5, calculate the sucess rate of the new correction function using the `validate` function from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e0bd407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8757225433526011\n",
      "Observed: rick\tCorrected: ricks\tActual: rich\n",
      "Observed: couse\tCorrected: course\tActual: cause\n",
      "Observed: looses\tCorrected: loose\tActual: loses\n",
      "Observed: folloy\tCorrected: follow\tActual: folly\n",
      "Observed: forme\tCorrected: former\tActual: form\n",
      "Observed: contentded\tCorrected: contended\tActual: contented\n",
      "Observed: leat\tCorrected: least\tActual: left\n",
      "Observed: borde\tCorrected: border\tActual: bored\n",
      "Observed: oll\tCorrected: all\tActual: oil\n",
      "Observed: dept\tCorrected: kept\tActual: debt\n",
      "Number of failed words: 215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'them'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correction_noisy_channel(x): \n",
    "    # TODO: return best correction candidate based on noisy channel model \n",
    "    if x in words:\n",
    "        return x\n",
    "    else:\n",
    "        can = candidates(x)\n",
    "        if len(can)>0:\n",
    "            p_w = np.array([language_model(c) for c in can])\n",
    "            p_x_w = np.array([error_model(x,c,0.01) for c in can])\n",
    "            return can[np.argmax(p_w*p_x_w)]\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "# TODO: calculate success rate\n",
    "failed1, success_rate = validate(correction_noisy_channel)\n",
    "print(success_rate)\n",
    "for right, c , wrong in failed1[:10]:\n",
    "    if wrong in words:\n",
    "        continue\n",
    "    print(f'Observed: {wrong}\\tCorrected: {c}\\tActual: {right}')\n",
    "\n",
    "print(f'Number of failed words: {len(failed1)}')\n",
    "\n",
    "\n",
    "assert success_rate == 0.8757225433526011\n",
    "correction_noisy_channel('tham')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77ae94",
   "metadata": {},
   "source": [
    "As you can see tham is now corrected correctly. Unigram models do not include context sensitive information, i.e. which words come before or after $x$. To improve our spelling correction even further we would need to extend the language model to consider the context."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e65af4112ca4c6fec3433a0add0d1eaf10def3473331cb252bd027fd87675b1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
