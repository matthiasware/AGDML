{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 - Spelling Correcting | NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "- Implement a language-model function for $P(w)$.\n",
    "- You must load the file \"data.txt\", filter the alphabetic expressions (tip: use regex) and calculate the frequencies of occurrences of the existing words.\n",
    "- What are the ten most frequent words and what is their probability of occurrence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "corpus = [w.lower() for w in re.findall(r'\\w+', open('data.txt').read())]\n",
    "words = collections.Counter(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def languageModel(word, n = sum(list(words.values()))):\n",
    "    return words[word] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w     freq(w)\tp(w) \n",
      " ------------------\n",
      "the     46220\t0.08\n",
      "of      25494\t0.05\n",
      "and     16778\t0.03\n",
      "in      13292\t0.02\n",
      "to      12640\t0.02\n",
      "a       10957\t0.02\n",
      "is       6592\t0.01\n",
      "it       5271\t0.01\n",
      "that     4527\t0.01\n",
      "by       4339\t0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<5}{:>8}\\t{:<4}\".format(\"w\", \"freq(w)\", \"p(w)\"), \"\\n\", \"-\"*18)\n",
    "for word, freq in words.most_common(10):\n",
    "    print(\"{:<5}{:8d}\\t{:0.2f}\".format(word, freq, languageModel(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "- Implement a function that creates a set of possible correction candidates $C_w$ for a given word $w$.\n",
    "- You do not need to concatenate operations!\n",
    "- To make things even simpler:\n",
    "    - You can ignore unknown words (words, that do not occur in our corpus)\n",
    "    - If non of the candidates is known, return the word itself.\n",
    "- What is the set of Candidates for the word \"frod\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# fthe ollowing functions were written by Peter Norvig ;) (https://norvig.com/spell-correct.html)\n",
    "def edits1(word):\n",
    "    letters    = string.ascii_lowercase\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def known(wordies): \n",
    "    return set(w for w in wordies if w in words)\n",
    "\n",
    "def candidates(word): \n",
    "    return (known([word]) or known(edits1(word)) or [word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'die', 'lie', 'nee', 'nice', 'nile', 'nine', 'nip', 'pie', 'tie', 'vie'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates(\"nie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food', 'ford', 'fro', 'from', 'rod'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates(\"frod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Model\n",
    "\n",
    "### Task 3\n",
    "- Implement a function `correction(word)`\n",
    "- If $w$ is a known word, then $P(w) > P(c^{(k)})$ and therefore return $w$.\n",
    "- If $w$ is unknown  $argmax_k P(c^{(k)})$ and return $c^{(k)}$.\n",
    "- If both $w$ and its corrections are unknown, return $w$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word): \n",
    "    return max(candidates(word), key=languageModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'half'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"halo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "The file `validate.csv` contains a list of evaluation data of the form:\n",
    "\n",
    "    \"right, misspelled\"\n",
    "\n",
    "### Task 4\n",
    "- Use the validation data set to test your first version of the spelling correction function.\n",
    "- What is your success rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def validate(correction, verbose=False):\n",
    "    with open(\"validate.csv\", \"r\") as file:\n",
    "        r = csv.reader(file)\n",
    "        testset = [row for row in r if row]\n",
    "    failed = []\n",
    "    if verbose:\n",
    "        print(\"  i{:>20}{:>20}{:>20}\".format(\"expected\", \"actual\", \"original\"))\n",
    "    for i, (right, wrong) in enumerate(testset):\n",
    "        c = correction(wrong)\n",
    "        if c != right: \n",
    "            failed.append((right, c, wrong))\n",
    "            if verbose:\n",
    "                print(\"{:3d}{:>20}{:>20}{:>20}\".format(i, right, c, wrong))\n",
    "    success_rate = 1 - len(failed) / len(testset)\n",
    "    return failed, success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7486033519553073\n"
     ]
    }
   ],
   "source": [
    "failed0, sr0 = validate(correction)\n",
    "print(sr0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Noise Channel Model\n",
    "### Task 5\n",
    "- Implement the Noice Channel Model as a new error model.\n",
    "- You can use the confusion matrices given below.\n",
    "- Revalidate your correction function and present your results.\n",
    "- Again you can confine your functions to only consider known words with edit distance one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# from \"A Spelling Correction Program Based on a Noisy Channel Model\" by Kernighan et all.\n",
    "with open('addconfusion.data', 'r') as file:\n",
    "    addmatrix=data=ast.literal_eval(file.read())\n",
    "with open('subconfusion.data', 'r') as file:\n",
    "    submatrix=data=ast.literal_eval(file.read())\n",
    "with open('revconfusion.data', 'r') as file:\n",
    "    revmatrix=data=ast.literal_eval(file.read())\n",
    "with open('delconfusion.data', 'r') as file:\n",
    "    delmatrix=data=ast.literal_eval(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_substitutions(L, R):\n",
    "    edits = []\n",
    "    if len(R) >= 1:\n",
    "        for c in string.ascii_lowercase:\n",
    "            word = L + c + R[1:]\n",
    "            if word in words:\n",
    "                edits.append((\"sub\", word, R[0] + c))\n",
    "    return edits\n",
    "\n",
    "def edit_transposes(L, R):\n",
    "    edits = []\n",
    "    if len(R) > 1:\n",
    "        word = L + R[1] + R[0] + R[2:]\n",
    "        #L + R[1] + R[0] + R[2:]\n",
    "        if word in words:\n",
    "            edits.append((\"rev\", word, R[0] + R[1]))\n",
    "    return edits\n",
    "\n",
    "def edit_deletes(L, R):\n",
    "    edits = []\n",
    "    if R != \"\":\n",
    "        if L == \"\":\n",
    "            word = L + R[1:]\n",
    "            ed = \"#\" + R[0]\n",
    "        else:\n",
    "            word = L + R[1:]\n",
    "            ed = L[-1] + R[0]\n",
    "        if word in words:\n",
    "            edits.append((\"del\", word, ed))\n",
    "    return edits\n",
    "\n",
    "def edit_adds(L, R):\n",
    "    edits = []\n",
    "    for c in string.ascii_lowercase:\n",
    "        if L == \"\":\n",
    "            word = L + c + R\n",
    "            xy = \"#\" + c\n",
    "        else:\n",
    "            word = L + c + R\n",
    "            xy = L[-1] + c\n",
    "        if word in words:\n",
    "            edits.append((\"add\", word,  xy))\n",
    "    return edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidates(word):\n",
    "    if known([word]):\n",
    "        return None\n",
    "    splits = [(word[:i], word[i:])  for i in range(len(word) + 1)]\n",
    "    edits = [f(L, R) for L, R in splits for f in [edit_adds, edit_deletes, edit_transposes, edit_substitutions]]\n",
    "    edits = [i for e in edits for i in e if i]\n",
    "    return edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorModel(edit, candidate, xy):\n",
    "    corpus = \" \".join(words)\n",
    "    x, y = xy\n",
    "    try:\n",
    "        if edit == 'add':\n",
    "            if x == '#':\n",
    "                return addmatrix[x+y]/corpus.count(' '+y)\n",
    "            else:\n",
    "                return addmatrix[x+y]/corpus.count(x)\n",
    "        if edit == 'sub':\n",
    "            return submatrix[(x+y)[0:2]]/corpus.count(y)\n",
    "        if edit == 'rev':\n",
    "            return revmatrix[x+y]/corpus.count(x+y)\n",
    "        if edit == 'del':\n",
    "            if x == '#':\n",
    "                return delmatrix[x+y]/corpus.count(' '+y)\n",
    "            else:\n",
    "                return delmatrix[x+y]/corpus.count(x+y)\n",
    "    except Exception as e:\n",
    "        print(x, y, edit, candidate)\n",
    "        raise Exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(edit, candidate , xy):\n",
    "    return languageModel(candidate) * errorModel(edit, candidate, xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def correction(word): \n",
    "    cs = candidates(word)\n",
    "    if cs:\n",
    "        idx = np.argmax([model(*c) for c in cs])\n",
    "        return cs[idx][1]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877094972067039\n"
     ]
    }
   ],
   "source": [
    "failed, sr = validate(correction)\n",
    "print(sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
