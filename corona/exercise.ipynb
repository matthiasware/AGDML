{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Prediction (30 Points)\n",
    "\n",
    "In this exercise, you will have a look on a different type of prediction problem: **time series prediction**.\n",
    "You will implement and evaluate the commonly used time series predictor SARIMA on the dataset of positive corona tests.\n",
    "\n",
    "In the event of a persistent problem, do not hesitate to contact the course instructors under\n",
    "- paul.kahlmeyer@uni-jena.de\n",
    "\n",
    "### Submission\n",
    "\n",
    "- Deadline of submission:\n",
    "        x.y.z\n",
    "- Submission on [moodle page](https://moodle.uni-jena.de/course/view.php?id=18310)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The global COVID-19 pandemic has led to the creation of enormous datasets, that let us evaluate the trend of the pandemic. \n",
    "\n",
    "Here we will use the daily updated [preprocessed dataset](https://www.kaggle.com/headsortails/covid19-tracking-germany) available on kaggle.\n",
    "Each row in this dataset is a daily report from a german county on reported cases of COVID-19. It contains the following attributes:\n",
    "\n",
    "- `state`: Name of german federal state (Bundesland)\n",
    "- `county`: Name of county (Landkreis)\n",
    "- `age_group`: age group of reported cases\n",
    "- `gender`: gender of reported cases\n",
    "- `date`: date of reporting\n",
    "- `cases`: number of reported positive tests\n",
    "- `deaths`: number of reported deaths\n",
    "- `recovered`: number of reported recovered cases\n",
    "\n",
    "\n",
    "In this task, we are only interested in the development of positive cases over time.\n",
    "\n",
    "As a sanity check, you can compare your solution with the official \n",
    "[Corona Dashboard](https://experience.arcgis.com/experience/478220a4c454480e823b17327b2bf1d4) of the RKI (here a \n",
    "[faster version](https://covid-karte.de/)).\n",
    "\n",
    "### Task 1 (7 Points)\n",
    "Load and prepare the dataset into a timeline that hold the number of reported positive cases over time.\n",
    "Plot the resulting timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: load data\n",
    "\n",
    "# TODO: process data\n",
    "\n",
    "# TODO: plot curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series prediction\n",
    "\n",
    "The problem of predicting the next value in a time series is fundamentaly different from the prediction problems we have seen so far, as the points in a time series do naturally depend on each other. \n",
    "\n",
    "First, we want to introduce a baseline predictor, against which we can compare our later predictors.\n",
    "\n",
    "### Task 2 (1 Point)\n",
    "\n",
    "An extremely simple predictor is the **naive predictor**, that predicts the last value of a time series as the next value. Implement and test this predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(time_series):\n",
    "    # TODO: return prediction of naive predictor\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to introduce a quality measure that evaluates the quality of a predictor.\n",
    "\n",
    "Let \n",
    "- $y_1,\\dots,y_n$ be a time series of lenght $n$\n",
    "- $m<n$ be an index of the time series\n",
    "- $p_k: \\mathbb{R}^k\\rightarrow \\mathbb{R}$ be a predictor, that predicts a next value for a given time series of length $k$\n",
    "- $d(y_i,\\hat{y}_i)$ be a distance measure between predicted and actual value\n",
    "\n",
    "**Walk forward validation** for a type of predictor $p_k$ is defined as \n",
    "\n",
    "\\begin{align}\n",
    "\\cfrac{1}{n-m}\\sum\\limits_{i=0}^{n-m-1}d\\left(y_{m+i+1}, p_{m+i}\\left(\\left[y_j\\right]_{j=1,\\dots,m+i}\\right)\\right)\n",
    "\\end{align}\n",
    "\n",
    "in other words, starting with the first $m$ steps of the time series, we determine the error of the predicted next value. We then walk one step forward in the time series (first $m+1$ steps) and repeat the process until we predicted the last value of the time series. The average prediction error is then reported as walk forward validation.\n",
    "\n",
    "### Task 3 (3 Points)\n",
    "\n",
    "Implement the `wfv` function, that takes as input:\n",
    "- `predictor`: A function, that takes as input a time series and outputs the predicted next value\n",
    "- `time series`: A time series\n",
    "- `s_perc`: percentage of the time series to start the walk forward validation with\n",
    "- `plot` : optional keyword, that lets you plot the predicted values vs. the actual values\n",
    "\n",
    "and outputs the [**Mean Absolute Error**](https://en.wikipedia.org/wiki/Mean_absolute_error) between the predictions and the actual values.\n",
    "\n",
    "Use your function to evaluate the naive predictor from Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def wfv(predictor, time_series, s_perc=0.2, plot=False):\n",
    "    # TODO: implement walk forward validation\n",
    "    pass\n",
    "\n",
    "# TODO: evaluate naive predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that the simple, naive predictor gets wrong, because there is an underlying seasonality within the time series.\n",
    "\n",
    "### Task 4 (1 Point)\n",
    "\n",
    "Implement the `naive_season` predictor, a generalization of the `naive` predictor.\n",
    "It that takes an additional seasonality parameter `s` and predicts the last value of the season (e.g. if we assume a seasonality of 3 days, it would predict the value from 3 days ago).\n",
    "\n",
    "Evaluate the `naive_season` predictor with walk forward validation and compare the result to the naive predictor (`s_perc`=0.2).\n",
    "\n",
    "Hint: You can use a [lambda function](https://realpython.com/python-lambda/) to quickly pass a function to `wfv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_season(time_series, s=1):\n",
    "    # TODO: return prediction of naive seasonal predictor\n",
    "    pass\n",
    "\n",
    "# TODO: evaluate naive seasonal predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA\n",
    "\n",
    "SARIMA models are a widely used approach for time series prediction. The general approach is to predict the next value by explaining auto-correlations in the time series.\n",
    "\n",
    "The name SARIMA is an acronym and stands for Seasonal AutoRegressive Integrated Moving Average.\n",
    "\n",
    "In order to make a prediction, one has to perform five steps:\n",
    "\n",
    "1. Make the time series stationary (**S,I**)\n",
    "2. Estimate the AutoRegressive Model using OLS (**AR**)\n",
    "3. Estimate the Moving Average Model using OLS (**MA**)\n",
    "4. Predict the next stationary value using 2. and 3.\n",
    "5. Make prediction unstationary again\n",
    "\n",
    "For further information, see [here](https://otexts.com/fpp2/arima.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the time series stationary\n",
    "\n",
    "Since we have a time series, the values do strongly depend on each other and we can not use any of our classical approaches, where we assumed i.i.d. data.\n",
    "\n",
    "A stationary time series is a time series, where the value does not depend on the time anymore and is equivalent to a random walk. Thus there is no dependence among the data due to time (e.g. periodicity, trend) and we can use classical approaches.\n",
    "\n",
    "A simple (and reversible) way of making a time series stationary is by **differenciating**.\n",
    "\n",
    "For a given time series $y_1,\\dots,y_n$, we create a new time series:\n",
    "\\begin{align}\n",
    "y_t' = y_{t}-y_{t-s}\\,\n",
    "\\end{align}\n",
    "\n",
    "where the integer $s$ is a seasonality parameter.\n",
    "\n",
    "In theory, we could differenciate the differenciated time series again, to make it even more stationary.\n",
    "The number of times one differenciates the time series is set by a hyperparameter $d$.\n",
    "However in practice (and especially here) it is often sufficient to set $d=1$, that is to differenciate only once.\n",
    "Therefore we will ignore this possibility.\n",
    "\n",
    "Note: If we set $s>1$, the model is called **S**ARIMA (S for seasonal).\n",
    "\n",
    "### Task 5 (2 Points)\n",
    "\n",
    "Implement the `differenciate` function and test it on the corona cases dataset.\n",
    "\n",
    "Think about the dataset: Which value for $s$ makes sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differenciate(time_series, s=1):\n",
    "    # TODO: differenciate the time series\n",
    "    pass\n",
    "    \n",
    "# TODO: differenciate corona time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Regressive Model\n",
    "\n",
    "In an auto regressive model, we assume the following model\n",
    "\\begin{align}\n",
    "y'_t &= \\theta_0+\\left(\\sum\\limits_{i=1}^{p}\\theta_i y'_{t-i} \\right)\\\\\n",
    "    &= \\begin{bmatrix}\n",
    "    \\theta_0\\\\\n",
    "    \\theta_1\\\\\n",
    "    \\vdots\\\\\n",
    "    \\theta_p\n",
    "    \\end{bmatrix}^T\n",
    "    \\begin{bmatrix}\n",
    "    1\\\\\n",
    "    y'_{t-1}\\\\\n",
    "    \\vdots\\\\\n",
    "    y'_{t-p}\n",
    "    \\end{bmatrix}\\,,\n",
    "\\end{align}\n",
    "\n",
    "where the next value of a time series is the result of an affine combination of the previous $p$ values.\n",
    "\n",
    "Note, how the estimation of $\\theta$ corresponds to the classical OLS problem.\n",
    "\n",
    "### Task 6 (2 Points)\n",
    "In order to make an Maximum Likelhood estimation, we need a dataset of samples $\\left[y'_i\\right]_{i=1,\\dots,p}$ and labels $y'_{p+1}$.\n",
    "\n",
    "Implement a function `time_series_dataset`, that takes a time series `time_series` and a window parameter `k` (corresponds to $p$) as input. The output should be a dataset of all possible sample label pairs as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_dataset(time_series, k):\n",
    "    # TODO: create time series dataset\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (3 Points)\n",
    "\n",
    "Implement the auto regressive model class `AR`.\n",
    "\n",
    "After $\\theta$ was estimated from a dataset, calculate the predictions\n",
    "\\begin{align}\n",
    "\\tilde{y'_t}:= \\theta_0+\\left(\\sum\\limits_{i=1}^{p}\\theta_i y'_{t-i} \\right)\n",
    "\\end{align}\n",
    "and the residuals \n",
    "\\begin{align}\n",
    "\\varepsilon_t := y'_t-\\tilde{y'_t}\n",
    "\\end{align}\n",
    "for each sample label pair of the dataset and save them as attributes of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "class AR():\n",
    "    \n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "        self.theta = None\n",
    "        self.intercept = None\n",
    "        self.predictions = None\n",
    "        self.residuals = None\n",
    "\n",
    "    def fit(self, time_series):\n",
    "        # TODO: estimate theta + intercept\n",
    "        \n",
    "        # TODO: calculate residuals\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def predict(self, time_series):\n",
    "        # TODO: predict next value\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 (2 Points)\n",
    "\n",
    "Now test your `AR` class on the stationary time series from Task 5.\n",
    "\n",
    "1. Fit the time AR model on the whole time series\n",
    "2. Plot the predictions of the AR model with the actual time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit AR on stationary series\n",
    "\n",
    "# TODO: plot predictions vs. stationary series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average Model\n",
    "\n",
    "The Moving Average Model models the residual $\\varepsilon_t$:\n",
    "\\begin{align}\n",
    "\\varepsilon_t &= \\phi_0+\\left(\\sum\\limits_{i=1}^{q}\\phi_i \\varepsilon_{t-i} \\right)\\\\\n",
    "    &= \\begin{bmatrix}\n",
    "    \\phi_0\\\\\n",
    "    \\phi_1\\\\\n",
    "    \\vdots\\\\\n",
    "    \\phi_p\n",
    "    \\end{bmatrix}^T\n",
    "    \\begin{bmatrix}\n",
    "    1\\\\\n",
    "    \\varepsilon_{t-1}\\\\\n",
    "    \\vdots\\\\\n",
    "    \\varepsilon_{t-q}\n",
    "    \\end{bmatrix}\\,,\n",
    "\\end{align}\n",
    "\n",
    "where the next residual time series is the result of an affine combination of the previous $q$ residuals.\n",
    "\n",
    "The estimation of $\\phi$ again corresponds to the classical OLS problem.\n",
    "\n",
    "\n",
    "### Task 9 (2 Points)\n",
    "\n",
    "Similar to Task 7, implement a Moving Average Model class `MA`.\n",
    "\n",
    "Test your class on the residuals from the `AR` object of Task 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "class MA():\n",
    "    def __init__(self, q):\n",
    "        self.q = q\n",
    "        self.phi = None\n",
    "        self.intercept = None\n",
    "        self.predictions = None\n",
    "\n",
    "    def fit(self, residual_series):\n",
    "        # TODO: estimate phi + intercept\n",
    "        \n",
    "        # TODO: calculate predictions\n",
    "        \n",
    "\n",
    "    def predict(self, residual_series):\n",
    "        # TODO: predict next residual\n",
    "    \n",
    "# TODO: test class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining AR and MA\n",
    "\n",
    "The model underlying SARIMA is simply the combination of the auto regressive and the moving average model on seasonally differenciated data:\n",
    "\\begin{align}\n",
    "y'_t = \\theta_0+\\left(\\sum\\limits_{i=1}^{p}\\theta_i y'_{t-i} \\right) + \\phi_0+\\left(\\sum\\limits_{i=1}^{q}\\phi_i \\varepsilon_{t-i} \\right)\n",
    "\\end{align}\n",
    "That is, the next value of our differenciated time series is a linear combination of the last $p$ values.\n",
    "However, this value is disturbed with noise, which is a linear combination of the last $q$ residuals.\n",
    "\n",
    "### Task 10 (4 Points)\n",
    "Implement the `SARIMA` predictor function and perform the walk forward validation (`s_perc`=0.2) with this predictor.\n",
    "Experiment, which values for $p,q,s$ yield good results and compare the results to the baselines.\n",
    "\n",
    "Note, that the predicted value still has to be undifferenciated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARIMA(time_series, p, q, s):\n",
    "    \n",
    "    # TODO: differenciate\n",
    "    \n",
    "    # TODO: auto regressive\n",
    "    \n",
    "    # TODO: moving average\n",
    "    \n",
    "    # TODO: combine predictions\n",
    "    \n",
    "    # TODO: undifferenciate\n",
    "    pass\n",
    "\n",
    "# TODO: Test predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided Package\n",
    "\n",
    "The Python library [statsmodels](https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima.model.ARIMA.html) provides an implementation of ARIMA models.\n",
    "\n",
    "\n",
    "### Task 11 (3 Points)\n",
    "Use the statsmodels implementation to fit an ARIMA model on the time series and compare the walk forward validation (`s_perc`=0.2) error with the previously obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: define predictor using statsmodels ARIMA\n",
    "\n",
    "# TODO: Test predictor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
